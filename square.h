
#ifndef _SQUARE_H_
#define _SQUARE_H_

//
// Generated by NVIDIA NVVM Compiler
// Compiler built on Sat Mar 15 09:52:22 2014 (1394848342)
// Cuda compilation tools, release 6.0, V6.0.1
//

/*
PTX is equivalent to the following kernel:

__global__
void squareKernel(int *data, int N)
{
	int i = blockIdx.x * blockDim.x + threadIdx.x;
	if(i < N)
	{
		data[i] = i * i;
	}
}
*/

char squarePtx64[] = "\n\
.version 4.0\n\
.target sm_20\n\
.address_size 64\n\
.visible .entry _Z12squareKernelPii(\n\
	.param .u64 _Z12squareKernelPii_param_0,\n\
	.param .u32 _Z12squareKernelPii_param_1\n\
)\n\
{\n\
	.reg .pred 	%p<2>;\n\
	.reg .s32 	%r<7>;\n\
	.reg .s64 	%rd<5>;\n\
	ld.param.u64 	%rd1, [_Z12squareKernelPii_param_0];\n\
	ld.param.u32 	%r2, [_Z12squareKernelPii_param_1];\n\
	mov.u32 	%r3, %ntid.x;\n\
	mov.u32 	%r4, %ctaid.x;\n\
	mov.u32 	%r5, %tid.x;\n\
	mad.lo.s32 	%r1, %r3, %r4, %r5;\n\
	setp.ge.s32	%p1, %r1, %r2;\n\
	@%p1 bra 	BB0_2;\n\
	cvta.to.global.u64 	%rd2, %rd1;\n\
	mul.lo.s32 	%r6, %r1, %r1;\n\
	mul.wide.s32 	%rd3, %r1, 4;\n\
	add.s64 	%rd4, %rd2, %rd3;\n\
	st.global.u32 	[%rd4], %r6;\n\
BB0_2:\n\
	ret;\n\
}\n\
";

#endif


